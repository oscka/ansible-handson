---

## vagrant 환경여부 체크(사용하는 곳 위마다 필요)
- name: check vagrant
  become: true
  shell: |
    if [ -d /home/vagrant ]; then echo 'vagrant'; else echo 'not_vagrant'; fi
  register: vagrant_check
  tags: 
    - k8s-multi-master
    - k8s-cluster-multi


## 원격 노드의 $HOME/ 디렉토리에서 작업하며 $HOME/cluster_initialized.txt 가 존재하지 않을 경우, shell 결과를 cluster_initialized.txt에 추가합니다.
### vagrant 로컬환경에서는 --apiserver-advertise-address 설정해줄 필요 있음. (aws 환경에서는 추가할 필요 없음)
- name: initialize the cluster (vagrant)
  become: true
  shell: |
    kubeadm init --control-plane-endpoint "{{hostvars[groups.lb4k8s.0].ansible_host}}:6443"  --pod-network-cidr=192.168.0.0/16 --apiserver-advertise-address={{HOST_IP}}
  register: output
  tags: 
    - k8s-multi-master
    - k8s-cluster-multi
  when: (hostvars[groups.masters.0].ansible_host == HOST_IP) and (vagrant_check.stdout == 'vagrant')

### vagrant가 아닐때
- name: initialize the cluster (not vagrant)
  become: true
  shell: |
    kubeadm init --control-plane-endpoint "{{hostvars[groups.lb4k8s.0].ansible_host}}:6443"  --pod-network-cidr=192.168.0.0/16 
  register: output
  tags: 
    - k8s-multi-master
    - k8s-cluster-multi
  when: (hostvars[groups.masters.0].ansible_host == HOST_IP) and (vagrant_check.stdout != 'vagrant')

#---out---
- debug:
    var: output
  tags: 
    - k8s-multi-master
    - k8s-cluster-multi
  when: hostvars[groups.masters.0].ansible_host == HOST_IP # master leader에서만 실행

- name: generate certificate and upload cluster
  become: true
  shell: |
    kubeadm init phase upload-certs --upload-certs | grep -vw -e certificate -e Namespace
  register: output_certificate
  tags: 
    - k8s-multi-master
    - k8s-cluster-multi
  when: hostvars[groups.masters.0].ansible_host == HOST_IP 

- debug:
    msg: "{{ output_certificate.stdout }}"
  tags: 
    - k8s-multi-master
    - k8s-cluster-multi
  when: hostvars[groups.masters.0].ansible_host == HOST_IP 

- name: set fact certificate_key
  set_fact:  # GLOBAL 변수로 선언(한 HOST안에서)
    CERTIFICATE_KEY: "{{ output_certificate.stdout_lines[0] }}"
  tags: 
    - k8s-multi-master
    - k8s-cluster-multi
  when: hostvars[groups.masters.0].ansible_host == HOST_IP 

- name: Get the token for joining the worker nodes
  become: true
  shell: kubeadm token create  --print-join-command
  register: kubernetes_join_command
  tags: 
    - k8s-multi-master
    - k8s-cluster-multi
  when: hostvars[groups.masters.0].ansible_host == HOST_IP 

- debug:
    msg: "{{ kubernetes_join_command.stdout }}"
  tags: 
    - k8s-multi-master
    - k8s-cluster-multi
  when: hostvars[groups.masters.0].ansible_host == HOST_IP 

- name: set fact join_command
  set_fact:
    JOIN_COMMAND: "{{ kubernetes_join_command.stdout_lines[0] }} "
  tags: 
    - k8s-multi-master
    - k8s-cluster-multi
  when: hostvars[groups.masters.0].ansible_host == HOST_IP 

######### master_join_command  upload to server########
- name: Copy master join command from Ansiblehost to the master nodes.
  become: true
  copy:
    src: "{{playbook_dir}}/join-script/master_join_command"
    dest: /tmp/master_join_command
    mode: 0777
  tags: 
    - k8s-multi-master
    - k8s-cluster-multi
  when: hostvars[groups.masters.0].ansible_host != HOST_IP  # master leader가 아닐 경우만 실행

## vagrant 환경여부 체크
- name: check vagrant
  become: true
  shell: |
    if [ -d /home/vagrant ]; then echo 'vagrant'; else echo 'not_vagrant'; fi
  register: vagrant_check
  tags: 
    - k8s-multi-master
    - k8s-cluster-multi

######### master_join_command  add option --apiserver-advertise-address ########
### vagrant 로컬환경에서는 apiserver ip 설정해줄 필요 있음.
### aws 환경에서는 추가할 필요 없음
- name: "[k8s-multi-master] add option --apiserver-advertise-address to /tmp/master_join_command"
  shell: |
    echo ' --apiserver-advertise-address={{HOST_IP}}' >> /tmp/master_join_command
  tags:
    - k8s-multi-master
    - k8s-cluster-multi
  when: (hostvars[groups.masters.0].ansible_host != HOST_IP) and (vagrant_check.stdout == 'vagrant')


######### Additional join  master 설치 ########
- name: Join the master nodes to the cluster.
  become: true
  command: sh /tmp/master_join_command
  register: output
  tags: 
    - k8s-multi-master
    - k8s-cluster-multi
  when: hostvars[groups.masters.0].ansible_host != HOST_IP 

#---out---
- debug:
    var: output
  tags: 
    - k8s-multi-master
    - k8s-cluster-multi
  when: hostvars[groups.masters.0].ansible_host != HOST_IP 


- name: create .kube directory
  become: true
  become_user: kube
  file:
    path: $HOME/.kube
    state: directory
    mode: 0755
  tags: 
    - k8s-multi-master
    - k8s-cluster-multi



- name: copies admin.conf to user's kube config
  become: true
  copy:
    src: /etc/kubernetes/admin.conf
    dest: /home/kube/.kube/config
    remote_src: yes
    owner: kube
  tags: 
    - k8s-multi-master
    - k8s-cluster-multi


##CNI (가상 Network) 적용
#### kubenet이라는 자체적인 CNI가 있지만 제한적 3rd-party CNI으로는 Calico, Canal, Clilum, Flannel, Weave등 다양항 CNI가 있다.
#### Calico 를 적용한다 
#### flannel : sudo kubectl apply -f https://raw.githubusercontent.com/flannel-io/flannel/master/Documentation/kube-flannel.yml
## Calico 기반 구축: pod-network-cidr=192.168.0.0/16
## Flannel 기반 구축: pod-network-cidr=10.244.0.0/16
- name: install Pod network
  become: true
  become_user: kube
  shell: kubectl apply -f https://raw.githubusercontent.com/projectcalico/calico/v3.24.1/manifests/calico.yaml 
  args:
    chdir: $HOME
  register: output
  tags: 
    - k8s-multi-master
    - k8s-cluster-multi

#---out---
- debug:
    var: output
  tags: 
    - k8s-multi-master
    - k8s-cluster-multi

- name: Copy join command for control plan to local file.
  local_action: copy content="{{JOIN_COMMAND}}  --control-plane --certificate-key {{CERTIFICATE_KEY}}" dest="{{playbook_dir}}/join-script/master_join_command" mode=0777
  tags: 
    - k8s-multi-master
    - k8s-cluster-multi
  when: hostvars[groups.masters.0].ansible_host == HOST_IP 

- name: Copy join command worker to local file.
  local_action: copy content="{{ JOIN_COMMAND }}" dest="{{playbook_dir}}/join-script/worker_join_command" mode=0777
  tags: 
    - k8s-multi-master
    - k8s-cluster-multi
  when: hostvars[groups.masters.0].ansible_host == HOST_IP 


#### fetch kubeconfig to local
- name: "k8s multi master fetch remote kubeconfig"
  ansible.builtin.fetch:
    src: /home/kube/.kube/config
    dest: "{{LOCAL_USER_HOME}}/.kube/k8s/kubeconfig"
    flat: yes
  # run_once: true   
  tags: 
    - k8s-multi-master
    - k8s-cluster-multi
  when: hostvars[groups.masters.0].ansible_host == HOST_IP 
## k8s kubeadmin으로 설치하면 --control-plane-endpoint로 설정하였기 때문에 아래 과정은 생략 가능 하다 
# - name: "k8s  multi master  kubeconfig remote.ip replace"
#   local_action: shell
#     sed -i '' 's/127.0.0.1/{{HOST_IP}}/' {{LOCAL_USER_HOME}}/.kube/k8s/kubeconfig
#   # run_once: true 
#   tags: 
#     - "test1"
#     - k8s-multi-master
#     - k8s-cluster-multi
#   when: hostvars[groups.masters.0].ansible_host == HOST_IP  


- name: "k8s wait pod ready  "
  shell: |
    kubectl wait pod --timeout=-1s --for=condition=Ready -l '!job-name' -n kube-system
  register: output
  tags: 
    - k8s-multi-master
    - k8s-cluster-multi

##### master cluster 삭제  #######
- name: master cluster 삭제 
  become: true
  shell: | 
    kubeadm reset -f
  tags: 
    - k8s-multi-master-delete
    - k8s-cluster-multi-delete
